{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "780a0c31",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import warnings\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "import seaborn as sns\n",
    "from stargazer.stargazer import Stargazer\n",
    "from sklearn.linear_model import LinearRegression, LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3c52864d",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('kickers_v2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d78ef53b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Team</th>\n",
       "      <th>Year</th>\n",
       "      <th>GameMinute</th>\n",
       "      <th>Kicker</th>\n",
       "      <th>Distance</th>\n",
       "      <th>ScoreDiff</th>\n",
       "      <th>Grass</th>\n",
       "      <th>Success</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>PHI</td>\n",
       "      <td>2005</td>\n",
       "      <td>3</td>\n",
       "      <td>Akers</td>\n",
       "      <td>49</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>PHI</td>\n",
       "      <td>2005</td>\n",
       "      <td>29</td>\n",
       "      <td>Akers</td>\n",
       "      <td>49</td>\n",
       "      <td>-7</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>PHI</td>\n",
       "      <td>2005</td>\n",
       "      <td>51</td>\n",
       "      <td>Akers</td>\n",
       "      <td>44</td>\n",
       "      <td>-7</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>PHI</td>\n",
       "      <td>2005</td>\n",
       "      <td>14</td>\n",
       "      <td>Akers</td>\n",
       "      <td>43</td>\n",
       "      <td>14</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>PHI</td>\n",
       "      <td>2005</td>\n",
       "      <td>60</td>\n",
       "      <td>Akers</td>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0 Team  Year  GameMinute Kicker  Distance  ScoreDiff  Grass  \\\n",
       "0           1  PHI  2005           3  Akers        49          0  False   \n",
       "1           2  PHI  2005          29  Akers        49         -7  False   \n",
       "2           3  PHI  2005          51  Akers        44         -7  False   \n",
       "3           4  PHI  2005          14  Akers        43         14   True   \n",
       "4           5  PHI  2005          60  Akers        23          0   True   \n",
       "\n",
       "   Success  \n",
       "0        0  \n",
       "1        0  \n",
       "2        1  \n",
       "3        0  \n",
       "4        1  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "304ad0ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# It's important we check for NAN before we start our analysis.\n",
    "data.isnull().values.any()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98907ad4",
   "metadata": {},
   "source": [
    "<h1> PSET 1 Econ 1042 Sports Economics </h1>\n",
    "<h2> 1. Question </h2>\n",
    "<ol>\n",
    "    <li> What was the minimum distance of a field goal kicked in this sample? What was the maximum? Mean? Median!</li>\n",
    "    <li> Why isn’t the minimum lower? (For those who are not familiar with football, please read about how field goal distance is measured and its relationship to where the ball is on the field.)</li>\n",
    "    <li> What special circumstances might explain the maximum? (Hint: football is a game with 4, 15-minute quarters. At the end of the second quarter there is a halftime break and possession is assigned based on the result of a first-half coin toss) </li>\n",
    "</ol>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6e467f50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The median distance of a field goal kicked was 37.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "count    11187.000000\n",
       "mean        36.897381\n",
       "std         10.173351\n",
       "min         18.000000\n",
       "25%         28.000000\n",
       "50%         37.000000\n",
       "75%         45.000000\n",
       "max         76.000000\n",
       "Name: Distance, dtype: float64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(f\"The median distance of a field goal kicked was {np.median(data['Distance'])}\")\n",
    "data['Distance'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "885af55a",
   "metadata": {},
   "source": [
    "1. The minimum distance of a field goal kicked in the sample was 18.00 yards. The maximum was 76.00 yards and the median was 37.0 yards. The mean was 36.897 yards\n",
    "2. The minimum is 17 yards. This makes sense since the endzone is 10yards, and the ball has to be kicked from 7 yards from the line of scrimmage. Hence 10 + 7 = 17."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2377c96d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Team</th>\n",
       "      <th>Year</th>\n",
       "      <th>GameMinute</th>\n",
       "      <th>Kicker</th>\n",
       "      <th>Distance</th>\n",
       "      <th>ScoreDiff</th>\n",
       "      <th>Grass</th>\n",
       "      <th>Success</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3557</th>\n",
       "      <td>3558</td>\n",
       "      <td>OAK</td>\n",
       "      <td>2008</td>\n",
       "      <td>30</td>\n",
       "      <td>Janikowski</td>\n",
       "      <td>76</td>\n",
       "      <td>15</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Unnamed: 0 Team  Year  GameMinute      Kicker  Distance  ScoreDiff  \\\n",
       "3557        3558  OAK  2008          30  Janikowski        76         15   \n",
       "\n",
       "      Grass  Success  \n",
       "3557   True        0  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Lets find out what play was kicked from 76 yards away?\n",
    "max_yard = data.loc[data['Distance'] == 76.00]\n",
    "max_yard"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b082f1c",
   "metadata": {},
   "source": [
    "3. The 76 yards field goal attempt from Janikowski was in the last second of the second quarter (video: https://www.youtube.com/watch?v=X7BepDe6Zoc). It makes sense to kick if far into the opponents end zone, if in the first half your team had the ball. Since, then the opposing team will start from further away from the kickers endzone. It's like as if the special team does a punt."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "671e0d2d",
   "metadata": {},
   "source": [
    "<h2> 2. Question </h2>\n",
    "<p> Over the entire sample what percentage of kicks from 40 to 45 yards were made? Kicks over 45 yards? <p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3ddc13c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11187\n",
      "1325\n",
      "11.844% of Kicks were from between 40-45 yards\n"
     ]
    }
   ],
   "source": [
    "sample_size = len(data)\n",
    "print(sample_size)\n",
    "# let's find the number of successful kicks from 40-45 yards\n",
    "kicks_40_45 = data.loc[(data['Distance'] > 40) & (data['Distance'] < 45)]\n",
    "print(len(kicks_40_45))\n",
    "# We find that 1325 kicks were made in that range\n",
    "success_40_45 = kicks_40_45['Success'].value_counts()\n",
    "# print(success_40_45)\n",
    "ratio_success = success_40_45[1]/(success_40_45[0] + success_40_45[1])\n",
    "ratio = (len(kicks_40_45)/sample_size) * 100\n",
    "print(f'{ratio:.3f}% of Kicks were from between 40-45 yards')\n",
    "\n",
    "# How many kicks were over 45 yards?\n",
    "# kicks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6aa068c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24.439% of Kicks were from between 40-45 yards\n"
     ]
    }
   ],
   "source": [
    "kicks_above_45 = data.loc[data['Distance'] > 45]\n",
    "ratio_above_45 = (len(kicks_above_45)/sample_size) * 100\n",
    "print(f'{ratio_above_45:.3f}% of Kicks were from between 40-45 yards')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9988943e",
   "metadata": {},
   "source": [
    "<h2> 3. Question </h2>\n",
    "<p> Was the make rate higher on grass or on turf? Is that difference statistically significant? Do you think this is the true effect of surface? Why or why not?  (Answer this by doing an OLS regression. For the entire assignment, let’s use the heteroskedasticity robust standard errors, r in stata or the equivalent in R)<br> <br>\n",
    "Let's compute the difference using $\\Delta = \\bar{Y}_{grass} - \\bar{Y}_{turf}$ we shall report standard errors as heteroscedasticity robust (HC2) \n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dd985180",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                Success   R-squared:                       0.001\n",
      "Model:                            OLS   Adj. R-squared:                  0.001\n",
      "Method:                 Least Squares   F-statistic:                     7.500\n",
      "Date:                Tue, 31 Jan 2023   Prob (F-statistic):            0.00618\n",
      "Time:                        11:19:54   Log-Likelihood:                -4845.9\n",
      "No. Observations:               11187   AIC:                             9696.\n",
      "Df Residuals:                   11185   BIC:                             9710.\n",
      "Df Model:                           1                                         \n",
      "Covariance Type:                  HC2                                         \n",
      "==============================================================================\n",
      "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "Grass         -0.0193      0.007     -2.739      0.006      -0.033      -0.005\n",
      "Intercept      0.8433      0.005    164.864      0.000       0.833       0.853\n",
      "==============================================================================\n",
      "Omnibus:                     3155.584   Durbin-Watson:                   1.995\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):             6555.427\n",
      "Skew:                          -1.781   Prob(JB):                         0.00\n",
      "Kurtosis:                       4.175   Cond. No.                         2.75\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors are heteroscedasticity robust (HC2)\n"
     ]
    }
   ],
   "source": [
    "# define response variable\n",
    "# statsmodel requires us to add a column where each value is 1 in order to compute intercept\n",
    "data['Intercept'] = 1\n",
    "# Since we find no NAN in our column\n",
    "print(data['Grass'].isnull().values.any())\n",
    "# We can conver the 'bool' values for Grass to the datatype 'int'\n",
    "data['Grass'] = data['Grass'].astype(int)\n",
    "Y = data[['Success']]\n",
    "X = data[['Grass', 'Intercept']]\n",
    "mod = sm.OLS(Y, X)\n",
    "res = mod.fit(cov_type='HC2')\n",
    "print(res.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1bb9edef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.01932925]]\n"
     ]
    }
   ],
   "source": [
    "# Let's also try the Sklearn Library\n",
    "# We can also use the Sklearn Library to do an OLS regression, but I don't think it has a summary function.\n",
    "X = data[['Grass']]\n",
    "reg = LinearRegression(fit_intercept=True).fit(X,Y)\n",
    "parameters = reg.get_params()\n",
    "print(reg.coef_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e4878e3",
   "metadata": {},
   "source": [
    "We find that the observed difference is statistically insignificant at the $\\alpha = 0.05$ level. It seems as if the surface does not have an impact on the observed average success rates of field goal kicks."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "171f63be",
   "metadata": {},
   "source": [
    "<h2> 4. Question </h2>\n",
    "<ol>\n",
    "    <li>\tHow is distance of attempt correlated with surface? What might explain this? (Coaches get to choose when to kick a field goal, one is never forced) </li>\n",
    "    <li> \tHow is distance correlated with make percentage? </li>\n",
    "</ol>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5f886e8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.002551996001227438\n",
      "-0.33693399701495164\n"
     ]
    }
   ],
   "source": [
    "# Let's calculate the correlation between the columns\n",
    "corr_surface = data['Distance'].corr(data['Grass'])\n",
    "corr_success = data['Distance'].corr(data['Success'])\n",
    "print(corr_surface)\n",
    "print(corr_success)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cac743f",
   "metadata": {},
   "source": [
    "The correlation coefficient for distance and or Grass is -0.0025, basically negligible. The correlation coefficiecnt for distance and success rates is -0.3369, meaning as distance increases the success rate goes down. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3f82c10",
   "metadata": {},
   "source": [
    "<h2> 5. Question </h2>\n",
    "<ol>\n",
    "    <li>What is the formula for omitted variable bias?</li>\n",
    "    <li><strong>Given (a) what should happen to the estimate of the effect of a kick being on grass when you add in distance? Verify this is true.</li>\n",
    "</ol>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ae29347",
   "metadata": {},
   "source": [
    "1. Ommitted variable bias arises when the regressor X is correlated with an omitted variable.\n",
    "The formula for omitted variable bias is <br>$\\hat{\\beta}_{1,OLS}= \\frac{Cov(y,x_1)}{Var(x_1)}$\n",
    "2. We can estimate the effect of the ommited bias by adding in distance. Since, success rate and grass type are uncorrelated, we should be able to see <strong> NO IDEA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "06b38d32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                Success   R-squared:                       0.114\n",
      "Model:                            OLS   Adj. R-squared:                  0.114\n",
      "Method:                 Least Squares   F-statistic:                     695.7\n",
      "Date:                Tue, 31 Jan 2023   Prob (F-statistic):          1.74e-285\n",
      "Time:                        11:19:55   Log-Likelihood:                -4171.1\n",
      "No. Observations:               11187   AIC:                             8348.\n",
      "Df Residuals:                   11184   BIC:                             8370.\n",
      "Df Model:                           2                                         \n",
      "Covariance Type:                  HC2                                         \n",
      "==============================================================================\n",
      "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "Grass         -0.0200      0.007     -3.004      0.003      -0.033      -0.007\n",
      "Distance      -0.0124      0.000    -37.218      0.000      -0.013      -0.012\n",
      "Intercept      1.2999      0.011    115.413      0.000       1.278       1.322\n",
      "==============================================================================\n",
      "Omnibus:                     2395.590   Durbin-Watson:                   1.982\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):             4232.201\n",
      "Skew:                          -1.449   Prob(JB):                         0.00\n",
      "Kurtosis:                       3.824   Cond. No.                         152.\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors are heteroscedasticity robust (HC2)\n"
     ]
    }
   ],
   "source": [
    "Y = data[['Success']]\n",
    "X = data[['Grass', 'Distance', 'Intercept']]\n",
    "mod = sm.OLS(Y, X)\n",
    "res = mod.fit(cov_type='HC2')\n",
    "print(res.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bcbafa82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                Success   R-squared:                       0.114\n",
      "Model:                            OLS   Adj. R-squared:                  0.114\n",
      "Method:                 Least Squares   F-statistic:                     695.7\n",
      "Date:                Tue, 31 Jan 2023   Prob (F-statistic):          1.74e-285\n",
      "Time:                        11:19:55   Log-Likelihood:                -4171.1\n",
      "No. Observations:               11187   AIC:                             8348.\n",
      "Df Residuals:                   11184   BIC:                             8370.\n",
      "Df Model:                           2                                         \n",
      "Covariance Type:                  HC2                                         \n",
      "==============================================================================\n",
      "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "Intercept      1.2999      0.011    115.413      0.000       1.278       1.322\n",
      "Grass         -0.0200      0.007     -3.004      0.003      -0.033      -0.007\n",
      "Distance      -0.0124      0.000    -37.218      0.000      -0.013      -0.012\n",
      "==============================================================================\n",
      "Omnibus:                     2395.590   Durbin-Watson:                   1.982\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):             4232.201\n",
      "Skew:                          -1.449   Prob(JB):                         0.00\n",
      "Kurtosis:                       3.824   Cond. No.                         152.\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors are heteroscedasticity robust (HC2)\n"
     ]
    }
   ],
   "source": [
    "mod = smf.ols(formula='Success ~ Grass + Distance', data=data).fit(cov_type='HC2')\n",
    "print(mod.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "da29a21c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Unnamed: 0', 'Team', 'Year', 'GameMinute', 'Kicker', 'Distance',\n",
       "       'ScoreDiff', 'Grass', 'Success', 'Intercept'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d807301",
   "metadata": {},
   "source": [
    "<h2> 6. Question </h2>\n",
    "<ol>\n",
    "    <li> Run an ols regression of kick success on distance, surface, point differential, and clock time. Interpret the coefficients. Does it seem like kickers do better or worse late in the game? Does the score of the game seem to effect them?</li>\n",
    "\n",
    "<li>Now add in kicker fixed effects (i.kicker in Stata), what do these correct for? How does adjusted r-squared change? </li>\n",
    "</ol>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ee316d1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                Success   R-squared:                       0.114\n",
      "Model:                            OLS   Adj. R-squared:                  0.114\n",
      "Method:                 Least Squares   F-statistic:                     347.8\n",
      "Date:                Tue, 31 Jan 2023   Prob (F-statistic):          1.07e-282\n",
      "Time:                        11:19:56   Log-Likelihood:                -4171.0\n",
      "No. Observations:               11187   AIC:                             8352.\n",
      "Df Residuals:                   11182   BIC:                             8389.\n",
      "Df Model:                           4                                         \n",
      "Covariance Type:                  HC2                                         \n",
      "==============================================================================\n",
      "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "Intercept      1.2987      0.013    101.462      0.000       1.274       1.324\n",
      "Distance      -0.0124      0.000    -37.158      0.000      -0.013      -0.012\n",
      "Grass         -0.0200      0.007     -3.004      0.003      -0.033      -0.007\n",
      "ScoreDiff     -0.0001      0.000     -0.285      0.776      -0.001       0.001\n",
      "GameMinute  4.408e-05      0.000      0.221      0.825      -0.000       0.000\n",
      "==============================================================================\n",
      "Omnibus:                     2395.605   Durbin-Watson:                   1.981\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):             4232.237\n",
      "Skew:                          -1.449   Prob(JB):                         0.00\n",
      "Kurtosis:                       3.824   Cond. No.                         225.\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors are heteroscedasticity robust (HC2)\n"
     ]
    }
   ],
   "source": [
    "mod = smf.ols(formula='Success ~ Distance + Grass + ScoreDiff + GameMinute', data=data).fit(cov_type='HC2')\n",
    "print(mod.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "335a421b",
   "metadata": {},
   "source": [
    "<p>1. The Game minute seems to have no statistically significant effect on Kicker performance. Furthermore, the point differential of the game does not seem to be statistically significant either, and also not affecting kicker success rates.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fcb958b5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                Success   R-squared:                       0.127\n",
      "Model:                            OLS   Adj. R-squared:                  0.121\n",
      "Method:                 Least Squares   F-statistic:                 8.581e+10\n",
      "Date:                Tue, 31 Jan 2023   Prob (F-statistic):               0.00\n",
      "Time:                        11:19:56   Log-Likelihood:                -4088.0\n",
      "No. Observations:               11187   AIC:                             8350.\n",
      "Df Residuals:                   11100   BIC:                             8987.\n",
      "Df Model:                          86                                         \n",
      "Covariance Type:                  HC2                                         \n",
      "===========================================================================================\n",
      "                              coef    std err          z      P>|z|      [0.025      0.975]\n",
      "-------------------------------------------------------------------------------------------\n",
      "Intercept                   1.2659      0.024     53.087      0.000       1.219       1.313\n",
      "C(Kicker)[T.Andersen]       0.0438      0.047      0.937      0.349      -0.048       0.136\n",
      "C(Kicker)[T.Andrus]        -0.3664      0.216     -1.693      0.090      -0.791       0.058\n",
      "C(Kicker)[T.Bailey]         0.1116      0.031      3.578      0.000       0.050       0.173\n",
      "C(Kicker)[T.Barth]          0.0775      0.033      2.337      0.019       0.013       0.142\n",
      "C(Kicker)[T.Bironas]        0.0760      0.029      2.668      0.008       0.020       0.132\n",
      "C(Kicker)[T.Boswell]        0.1248      0.046      2.693      0.007       0.034       0.216\n",
      "C(Kicker)[T.Brien]         -0.4597      0.275     -1.674      0.094      -0.998       0.079\n",
      "C(Kicker)[T.Brindza]       -0.2372      0.153     -1.553      0.121      -0.537       0.062\n",
      "C(Kicker)[T.Brown]          0.0311      0.026      1.188      0.235      -0.020       0.082\n",
      "C(Kicker)[T.Bryant]         0.0572      0.028      2.079      0.038       0.003       0.111\n",
      "C(Kicker)[T.Buehler]       -0.0320      0.078     -0.411      0.681      -0.184       0.120\n",
      "C(Kicker)[T.Bullock]        0.0350      0.044      0.801      0.423      -0.051       0.121\n",
      "C(Kicker)[T.Carney]         0.0037      0.035      0.105      0.916      -0.065       0.073\n",
      "C(Kicker)[T.Carpenter]      0.0690      0.029      2.375      0.018       0.012       0.126\n",
      "C(Kicker)[T.Catanzaro]      0.0925      0.040      2.292      0.022       0.013       0.172\n",
      "C(Kicker)[T.Coons]          0.0628      0.055      1.150      0.250      -0.044       0.170\n",
      "C(Kicker)[T.Cortez]        -0.1175      0.108     -1.085      0.278      -0.330       0.095\n",
      "C(Kicker)[T.Coutu]         -0.7064      0.022    -32.777      0.000      -0.749      -0.664\n",
      "C(Kicker)[T.Crosby]         0.0113      0.029      0.392      0.695      -0.045       0.068\n",
      "C(Kicker)[T.Cundiff]       -0.0331      0.035     -0.943      0.346      -0.102       0.036\n",
      "C(Kicker)[T.Dawson]         0.0607      0.027      2.220      0.026       0.007       0.114\n",
      "C(Kicker)[T.Edinger]       -0.0719      0.079     -0.915      0.360      -0.226       0.082\n",
      "C(Kicker)[T.Elam]           0.0350      0.035      1.004      0.315      -0.033       0.103\n",
      "C(Kicker)[T.Elling]        -0.5950      0.023    -25.669      0.000      -0.640      -0.550\n",
      "C(Kicker)[T.Feely]          0.0476      0.029      1.634      0.102      -0.010       0.105\n",
      "C(Kicker)[T.Folk]           0.0112      0.031      0.363      0.717      -0.050       0.072\n",
      "C(Kicker)[T.Forbath]        0.0543      0.045      1.213      0.225      -0.033       0.142\n",
      "C(Kicker)[T.France]        -0.0472      0.134     -0.353      0.724      -0.309       0.215\n",
      "C(Kicker)[T.Franks]         0.0361      0.091      0.398      0.691      -0.142       0.214\n",
      "C(Kicker)[T.Freese]        -0.3562      0.159     -2.245      0.025      -0.667      -0.045\n",
      "C(Kicker)[T.Gano]           0.0173      0.034      0.510      0.610      -0.049       0.084\n",
      "C(Kicker)[T.Gostkowski]     0.0601      0.027      2.238      0.025       0.007       0.113\n",
      "C(Kicker)[T.Gould]          0.0664      0.027      2.448      0.014       0.013       0.120\n",
      "C(Kicker)[T.Graham]         0.0374      0.029      1.311      0.190      -0.019       0.093\n",
      "C(Kicker)[T.Gramatica]      0.0166      0.083      0.200      0.842      -0.147       0.180\n",
      "C(Kicker)[T.Hall]           0.0287      0.071      0.402      0.687      -0.111       0.168\n",
      "C(Kicker)[T.Hanson]         0.0673      0.031      2.181      0.029       0.007       0.128\n",
      "C(Kicker)[T.Hartley]        0.0105      0.041      0.257      0.797      -0.070       0.091\n",
      "C(Kicker)[T.Hauschka]       0.0743      0.030      2.445      0.014       0.015       0.134\n",
      "C(Kicker)[T.Henery]         0.0183      0.042      0.440      0.660      -0.063       0.100\n",
      "C(Kicker)[T.Hocker]        -0.0916      0.118     -0.775      0.438      -0.323       0.140\n",
      "C(Kicker)[T.Hopkins]        0.1042      0.056      1.861      0.063      -0.006       0.214\n",
      "C(Kicker)[T.Janikowski]     0.0514      0.029      1.802      0.072      -0.005       0.107\n",
      "C(Kicker)[T.Kaeding]        0.0432      0.031      1.396      0.163      -0.017       0.104\n",
      "C(Kicker)[T.Kasay]          0.0653      0.030      2.186      0.029       0.007       0.124\n",
      "C(Kicker)[T.Koenen]        -0.4115      0.137     -3.005      0.003      -0.680      -0.143\n",
      "C(Kicker)[T.Lambo]          0.0743      0.067      1.101      0.271      -0.058       0.207\n",
      "C(Kicker)[T.Lindell]        0.0325      0.030      1.086      0.277      -0.026       0.091\n",
      "C(Kicker)[T.Longwell]       0.0408      0.032      1.268      0.205      -0.022       0.104\n",
      "C(Kicker)[T.Mare]          -0.0100      0.033     -0.301      0.763      -0.075       0.055\n",
      "C(Kicker)[T.McManus]        0.0631      0.049      1.295      0.195      -0.032       0.159\n",
      "C(Kicker)[T.Medlock]       -0.1423      0.131     -1.083      0.279      -0.400       0.115\n",
      "C(Kicker)[T.Mehlhaff]      -0.1027      0.264     -0.388      0.698      -0.621       0.416\n",
      "C(Kicker)[T.Murray]         0.1003      0.086      1.165      0.244      -0.068       0.269\n",
      "C(Kicker)[T.Myers]          0.0621      0.066      0.946      0.344      -0.067       0.191\n",
      "C(Kicker)[T.Nedney]         0.0743      0.033      2.231      0.026       0.009       0.140\n",
      "C(Kicker)[T.Novak]          0.0325      0.034      0.963      0.336      -0.034       0.099\n",
      "C(Kicker)[T.Nugent]         0.0083      0.030      0.275      0.783      -0.051       0.068\n",
      "C(Kicker)[T.Parkey]         0.0666      0.055      1.205      0.228      -0.042       0.175\n",
      "C(Kicker)[T.Peterson]       0.0538      0.057      0.943      0.345      -0.058       0.165\n",
      "C(Kicker)[T.Pettrey]       -0.4034      0.253     -1.597      0.110      -0.899       0.092\n",
      "C(Kicker)[T.Potter]        -0.0665      0.203     -0.328      0.743      -0.465       0.331\n",
      "C(Kicker)[T.Prater]         0.0531      0.031      1.718      0.086      -0.007       0.114\n",
      "C(Kicker)[T.Rackers]        0.0531      0.029      1.801      0.072      -0.005       0.111\n",
      "C(Kicker)[T.Rayner]        -0.0642      0.050     -1.293      0.196      -0.161       0.033\n",
      "C(Kicker)[T.Reed]           0.0236      0.032      0.731      0.465      -0.040       0.087\n",
      "C(Kicker)[T.Santos]         0.0574      0.045      1.283      0.200      -0.030       0.145\n",
      "C(Kicker)[T.Schmitt]       -0.1605      0.368     -0.436      0.663      -0.881       0.560\n",
      "C(Kicker)[T.Scifres]        0.2547      0.021     12.298      0.000       0.214       0.295\n",
      "C(Kicker)[T.Scobee]         0.0329      0.030      1.088      0.277      -0.026       0.092\n",
      "C(Kicker)[T.Stitser]       -0.0093      0.135     -0.068      0.946      -0.275       0.256\n",
      "C(Kicker)[T.Stover]         0.0453      0.032      1.403      0.161      -0.018       0.109\n",
      "C(Kicker)[T.Sturgis]        0.0080      0.044      0.180      0.857      -0.079       0.095\n",
      "C(Kicker)[T.Succop]         0.0420      0.033      1.272      0.203      -0.023       0.107\n",
      "C(Kicker)[T.Suisham]        0.0298      0.030      1.005      0.315      -0.028       0.088\n",
      "C(Kicker)[T.Tucker]         0.1047      0.031      3.350      0.001       0.043       0.166\n",
      "C(Kicker)[T.Tynes]         -0.0130      0.032     -0.408      0.683      -0.075       0.049\n",
      "C(Kicker)[T.Vanderjagt]    -0.0203      0.058     -0.349      0.727      -0.134       0.094\n",
      "C(Kicker)[T.Vinatieri]      0.0619      0.027      2.275      0.023       0.009       0.115\n",
      "C(Kicker)[T.Walsh]          0.0711      0.035      2.031      0.042       0.002       0.140\n",
      "C(Kicker)[T.Wilkins]        0.0438      0.042      1.043      0.297      -0.039       0.126\n",
      "C(Kicker)[T.Zuerlein]       0.0277      0.041      0.681      0.496      -0.052       0.107\n",
      "Distance                   -0.0125      0.000    -37.174      0.000      -0.013      -0.012\n",
      "Grass                      -0.0246      0.007     -3.314      0.001      -0.039      -0.010\n",
      "ScoreDiff               -3.034e-05      0.000     -0.083      0.934      -0.001       0.001\n",
      "GameMinute               4.117e-05      0.000      0.207      0.836      -0.000       0.000\n",
      "==============================================================================\n",
      "Omnibus:                     2348.948   Durbin-Watson:                   2.007\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):             4107.577\n",
      "Skew:                          -1.426   Prob(JB):                         0.00\n",
      "Kurtosis:                       3.827   Cond. No.                     5.45e+03\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors are heteroscedasticity robust (HC2)\n",
      "[2] The condition number is large, 5.45e+03. This might indicate that there are\n",
      "strong multicollinearity or other numerical problems.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/deep/lib/python3.10/site-packages/statsmodels/base/model.py:1871: ValueWarning: covariance of constraints does not have full rank. The number of constraints is 86, but rank is 85\n",
      "  warnings.warn('covariance of constraints does not have full '\n"
     ]
    }
   ],
   "source": [
    "mod = smf.ols(formula='Success ~ Distance + Grass + ScoreDiff + GameMinute + C(Kicker)', data=data).fit(cov_type='HC2')\n",
    "print(mod.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb7bcc99",
   "metadata": {},
   "source": [
    "<p> 2. Adjusted R-square goes up, since we adjusting our regression for individuals attributes that do not vary over the time of a season(sample size)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "685ebdb9",
   "metadata": {},
   "source": [
    "<h2> 7. Question </h2>\n",
    "<ol>\n",
    "    <li> After you run the regression in part 6, do the command to predict fitted values from this regression: “predict, xb” in stata and equivalent in R “predict.lm”. Based on this, what would you predict the probability of Justin Tucker cutting the lead to 8 (scorediff was -11) in 2015, when the gameminute was 30, and he was on turf</li>\n",
    "    <ol>\n",
    "        <li> We can't build a model using all inputs, and then try to predict sth when missing one value. Missing here is an input for the <strong>Distance</li>\n",
    "    </ol>\n",
    "\n",
    "<li>Does this estimate strike you as reasonable?</li>\n",
    "<li>What would the estimate be for an average kicker?</li>\n",
    "</ol>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "9cc9e1cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.93507468])"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_tucker = data.loc[data['Kicker'] == 'Tucker']\n",
    "X = data_tucker[['Intercept', 'Distance', 'Grass', 'ScoreDiff', 'GameMinute']]\n",
    "Y = data_tucker[['Success']]\n",
    "reg_ols_tucker = sm.OLS(Y,X).fit(cov_type='HC2')\n",
    "reg_ols_tucker.predict([1,30, False, -11, 30])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e475672d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Linear_Tucker', -0.012015139013776488, 0.09939115007000607, 0.0008766873127663746, 0.0007538568196675142, 0.9350746758606505]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/deep/lib/python3.10/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but LinearRegression was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Distance</th>\n",
       "      <th>Grass</th>\n",
       "      <th>ScoreDiff</th>\n",
       "      <th>GameMinute</th>\n",
       "      <th>Proba</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Linear_Tucker</td>\n",
       "      <td>-0.012015</td>\n",
       "      <td>0.099391</td>\n",
       "      <td>0.000877</td>\n",
       "      <td>0.000754</td>\n",
       "      <td>0.935075</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Model  Distance     Grass  ScoreDiff  GameMinute     Proba\n",
       "0  Linear_Tucker -0.012015  0.099391   0.000877    0.000754  0.935075"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's use the Sklearn library for this prediction. Since we can specify the input.\n",
    "# Since we are interested in Tucker\n",
    "data_tucker = data.loc[data['Kicker'] == 'Tucker']\n",
    "X = data_tucker[['Distance', 'Grass', 'ScoreDiff', 'GameMinute']]\n",
    "Y = data_tucker[['Success']]\n",
    "reg = LinearRegression(fit_intercept=True).fit(X,Y)\n",
    "parameters = reg.get_params()\n",
    "# Let's find the distance of the kick from tucker with scroediff -11, gameminute 30, and on turf\n",
    "tucker = data_tucker.loc[(data_tucker['ScoreDiff']==-11)&(data_tucker['GameMinute']==30) & (data_tucker['Grass']==False)]\n",
    "tucker\n",
    "\n",
    "reg_coef = list(np.ravel(reg.coef_))\n",
    "reg_coef.insert(0, 'Linear_Tucker')\n",
    "proba = reg.predict([[30, False, -11, 30]])[0][0]\n",
    "reg_coef.append(proba)\n",
    "print(reg_coef)\n",
    "results = pd.DataFrame([reg_coef], columns=['Model', 'Distance', 'Grass', 'ScoreDiff', 'GameMinute', 'Proba'])\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5dfa1c23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9350746758606505\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/deep/lib/python3.10/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but LinearRegression was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# This is the play that the question is asking for\n",
    "# We can ignore the warning message\n",
    "tucker = [[30, False, -11, 30]]\n",
    "print(reg.predict(tucker)[0][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5023ef4",
   "metadata": {},
   "source": [
    "2. Let's see if this estimate seems reasonable for Tucker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4f99f6f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    61\n",
       "Name: Success, dtype: int64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tucker_35_yards = data_tucker.loc[(data_tucker['Distance'] < 35)]\n",
    "tucker_35_yards['Success'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "779d7e09",
   "metadata": {},
   "source": [
    "In the sample Tucker made $61$ kicks that were below 35 yards and he made every single one of them. Hence, the estimate in 1.) seems reasonable. On average in the sample we have $4765$ observations of Kicks that were shot at less then 35 yard distance. Of those $0.947\\%$ were successful, hence the predicted probability seems to be a reasonable estimate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "85054ece",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    4513\n",
       "0     252\n",
       "Name: Success, dtype: int64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_35_yards = data.loc[data['Distance'] < 35]\n",
    "data_35_yards['Success'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ace9ee9e",
   "metadata": {},
   "source": [
    "3. Let's predict the probability for an average kicker for that same shot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "7dfea5db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.93001065])"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# using the Statsmodels library\n",
    "X = data[['Intercept', 'Distance', 'Grass', 'ScoreDiff', 'GameMinute']]\n",
    "Y = data[['Success']]\n",
    "reg_ols = sm.OLS(Y,X).fit(cov_type='HC2')\n",
    "reg_ols.predict([1,30, False, -11, 30])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "23a90f24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Linear', -0.012371812687093085, -0.01997241577141623, -0.0001022378401408906, 4.407522836155251e-05, 0.9300106512280658]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/deep/lib/python3.10/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but LinearRegression was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Distance</th>\n",
       "      <th>Grass</th>\n",
       "      <th>ScoreDiff</th>\n",
       "      <th>GameMinute</th>\n",
       "      <th>Proba</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Linear</td>\n",
       "      <td>-0.012372</td>\n",
       "      <td>-0.019972</td>\n",
       "      <td>-0.000102</td>\n",
       "      <td>0.000044</td>\n",
       "      <td>0.930011</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Model  Distance     Grass  ScoreDiff  GameMinute     Proba\n",
       "0  Linear -0.012372 -0.019972  -0.000102    0.000044  0.930011"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = data[['Distance', 'Grass', 'ScoreDiff', 'GameMinute']]\n",
    "Y = data[['Success']]\n",
    "reg = LinearRegression(fit_intercept=True).fit(X,Y)\n",
    "parameters = reg.get_params()\n",
    "reg_coef = list(np.ravel(reg.coef_))\n",
    "reg_coef.insert(0, 'Linear')\n",
    "proba = reg.predict([[30, False, -11, 30]])[0][0]\n",
    "reg_coef.append(proba)\n",
    "print(reg_coef)\n",
    "results = pd.DataFrame([reg_coef], columns=['Model', 'Distance', 'Grass', 'ScoreDiff', 'GameMinute', 'Proba'])\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51f9f84a",
   "metadata": {},
   "source": [
    "We estimate the probability for an average kicker to be 0.93%"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a2c322b",
   "metadata": {},
   "source": [
    "<hr>\n",
    "<h2> 8. Question </h2>\n",
    "<ol>\n",
    "    <li>Now run a logistic regression with the same specification as in question 6. Use the command predict. Now what is the predicted probability of Tucker making that field goal? (the predict command in stata is now just “predict”)</li>\n",
    "    <li>Why do the coefficients look so different for the logistic regression vs. OLS </li>\n",
    "</ol>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "0b510287",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We find the prediction for success to be 0.9400650349065655\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/deep/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/deep/lib/python3.10/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but LogisticRegression was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Distance</th>\n",
       "      <th>Grass</th>\n",
       "      <th>ScoreDiff</th>\n",
       "      <th>GameMinute</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.102843</td>\n",
       "      <td>-0.168124</td>\n",
       "      <td>-0.000962</td>\n",
       "      <td>0.000384</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Distance     Grass  ScoreDiff  GameMinute\n",
       "0 -0.102843 -0.168124  -0.000962    0.000384"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = data[['Distance', 'Grass', 'ScoreDiff', 'GameMinute']]\n",
    "Y = data['Success']\n",
    "model_log = LogisticRegression(fit_intercept=True, penalty='none').fit(X,Y)\n",
    "parameters = model_log.get_params()\n",
    "pred = model_log.predict_proba([[30, False, -11, 30]])\n",
    "model_log_coef = [list(np.ravel(model_log.coef_))]\n",
    "print(f'We find the prediction for success to be {pred[0][1]}')\n",
    "coef = pd.DataFrame(model_log_coef, columns=['Distance', 'Grass', 'ScoreDiff', 'GameMinute'])\n",
    "# print(f'The coefficiencts are the following for Respective Distance, Grass, ScoreDiff, GameMinute -> {model_log_coef}')\n",
    "coef"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "36d086f9",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.390574\n",
      "         Iterations 7\n",
      "[0.94006474]\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:                Success   No. Observations:                11187\n",
      "Model:                          Logit   Df Residuals:                    11182\n",
      "Method:                           MLE   Df Model:                            4\n",
      "Date:                Tue, 31 Jan 2023   Pseudo R-squ.:                  0.1352\n",
      "Time:                        12:11:23   Log-Likelihood:                -4369.4\n",
      "converged:                       True   LL-Null:                       -5052.5\n",
      "Covariance Type:            nonrobust   LLR p-value:                1.436e-294\n",
      "==============================================================================\n",
      "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "Intercept      5.8159      0.151     38.605      0.000       5.521       6.111\n",
      "Distance      -0.1028      0.003    -32.715      0.000      -0.109      -0.097\n",
      "Grass         -0.1681      0.055     -3.072      0.002      -0.275      -0.061\n",
      "ScoreDiff     -0.0010      0.003     -0.332      0.740      -0.007       0.005\n",
      "GameMinute     0.0004      0.002      0.236      0.813      -0.003       0.004\n",
      "==============================================================================\n"
     ]
    }
   ],
   "source": [
    "# let's make it a bit prettier using the Stagazer library and the statsmodels package\n",
    "X = data[['Intercept', 'Distance', 'Grass', 'ScoreDiff', 'GameMinute']]\n",
    "log = sm.Logit(Y,X).fit()\n",
    "pred = log.predict([1,30,False, -11, 30])\n",
    "# print(log.predict([1, 30, False, -11, 30]))\n",
    "# print(log.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "e99986f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table style=\"text-align:center\"><tr><td colspan=\"3\" style=\"border-bottom: 1px solid black\"></td></tr><tr><td style=\"text-align:left\"></td><td colspan=\"2\"><em>Dependent variable:Success</em></td></tr><tr><td style=\"text-align:left\"></td><tr><td></td><td colspan=\"1\">OLS Model</td><td colspan=\"1\">Logit Model</td></tr><tr><td style=\"text-align:left\"></td><td>(1)</td><td>(2)</td></tr><tr><td colspan=\"3\" style=\"border-bottom: 1px solid black\"></td></tr><tr><td style=\"text-align:left\">Intercept</td><td>1.299<sup>***</sup></td><td>5.816<sup>***</sup></td></tr><tr><td style=\"text-align:left\"></td><td>(0.013)</td><td>(0.151)</td></tr><tr><td style=\"text-align:left\">Distance</td><td>-0.012<sup>***</sup></td><td>-0.103<sup>***</sup></td></tr><tr><td style=\"text-align:left\"></td><td>(0.000)</td><td>(0.003)</td></tr><tr><td style=\"text-align:left\">Grass</td><td>-0.020<sup>***</sup></td><td>-0.168<sup>***</sup></td></tr><tr><td style=\"text-align:left\"></td><td>(0.007)</td><td>(0.055)</td></tr><tr><td style=\"text-align:left\">ScoreDiff</td><td>-0.000<sup></sup></td><td>-0.001<sup></sup></td></tr><tr><td style=\"text-align:left\"></td><td>(0.000)</td><td>(0.003)</td></tr><tr><td style=\"text-align:left\">GameMinute</td><td>0.000<sup></sup></td><td>0.000<sup></sup></td></tr><tr><td style=\"text-align:left\"></td><td>(0.000)</td><td>(0.002)</td></tr><td colspan=\"3\" style=\"border-bottom: 1px solid black\"></td></tr><tr><td style=\"text-align: left\">Observations</td><td>11,187</td><td>11,187</td></tr><tr><td style=\"text-align: left\">R<sup>2</sup></td><td>0.114</td><td></td></tr><tr><td style=\"text-align: left\">Adjusted R<sup>2</sup></td><td>0.114</td><td></td></tr><tr><td style=\"text-align: left\">Residual Std. Error</td><td>0.351 (df=11182)</td><td>1.000 (df=11182)</td></tr><tr><td style=\"text-align: left\">F Statistic</td><td>347.846<sup>***</sup> (df=4; 11182)</td><td><sup></sup> (df=4; 11182)</td></tr><tr><td colspan=\"3\" style=\"border-bottom: 1px solid black\"></td></tr><tr><td style=\"text-align: left\">Note:</td>\n",
       " <td colspan=\"2\" style=\"text-align: right\">\n",
       "  <sup>*</sup>p&lt;0.1;\n",
       "  <sup>**</sup>p&lt;0.05;\n",
       "  <sup>***</sup>p&lt;0.01\n",
       " </td></tr></table>"
      ],
      "text/plain": [
       "<stargazer.stargazer.Stargazer at 0x287f85180>"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models = [reg_ols, log]\n",
    "table = Stargazer(models)\n",
    "table.custom_columns(['OLS Model', 'Logit Model'], [1, 1])\n",
    "table.covariate_order(['Intercept', 'Distance', 'Grass', 'ScoreDiff', 'GameMinute'])\n",
    "table"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2616b8ee",
   "metadata": {},
   "source": [
    "2. Why do the coefficients look so different for the logistic regression vs. OLS <br>\n",
    "\n",
    "Inherently a logit model and an OLS model are two different models. The logit model uses a sigmoid function, whereas the OLS model uses a simple linear function. Naturally, we end up with different coefficient values."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1176079e",
   "metadata": {},
   "source": [
    "<hline>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "923d71d2",
   "metadata": {},
   "source": [
    "<hr>\n",
    "<h2> 9. Question </h2>\n",
    "<ol>\n",
    "    <li> Who would you say was the best kicker in the NFL over this period? Why? Define best in at least two different ways. Try to quantify the size of the difference. </li>\n",
    "    <li> Are these differences stable over time? For example, if players switch team or year over year? </li>\n",
    "</ol>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "42f79688",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Team</th>\n",
       "      <th>Year</th>\n",
       "      <th>GameMinute</th>\n",
       "      <th>Kicker</th>\n",
       "      <th>Distance</th>\n",
       "      <th>ScoreDiff</th>\n",
       "      <th>Grass</th>\n",
       "      <th>Success</th>\n",
       "      <th>Intercept</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>302</th>\n",
       "      <td>303</td>\n",
       "      <td>BAL</td>\n",
       "      <td>2005</td>\n",
       "      <td>30</td>\n",
       "      <td>Elling</td>\n",
       "      <td>54</td>\n",
       "      <td>-17</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Unnamed: 0 Team  Year  GameMinute  Kicker  Distance  ScoreDiff  Grass  \\\n",
       "302         303  BAL  2005          30  Elling        54        -17      0   \n",
       "\n",
       "     Success  Intercept  \n",
       "302        0          1  "
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.loc[data['Kicker'] == 'Elling']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "403b6b6c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Kicker</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>Boswell</td>\n",
       "      <td>0.923077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Peterson</td>\n",
       "      <td>0.920000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>Hopkins</td>\n",
       "      <td>0.896552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>Bailey</td>\n",
       "      <td>0.895062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>Catanzaro</td>\n",
       "      <td>0.893939</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Koenen</td>\n",
       "      <td>0.307692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Brien</td>\n",
       "      <td>0.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Elling</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>Coutu</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>Scifres</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>83 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Kicker  Accuracy\n",
       "75    Boswell  0.923077\n",
       "28   Peterson  0.920000\n",
       "80    Hopkins  0.896552\n",
       "58     Bailey  0.895062\n",
       "69  Catanzaro  0.893939\n",
       "..        ...       ...\n",
       "21     Koenen  0.307692\n",
       "2       Brien  0.250000\n",
       "11     Elling       NaN\n",
       "59      Coutu       NaN\n",
       "61    Scifres       NaN\n",
       "\n",
       "[83 rows x 2 columns]"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# How do we define best kicker? A good kicker is one that makes most of the kicks? \n",
    "# Let's try the approach where the best kicker is the most accurate e.g makes most of their Kicks regardless of distance\n",
    "\n",
    "kicker_list = data['Kicker'].unique()\n",
    "\n",
    "def data_per_kicker(kickers):\n",
    "    accuracies = []\n",
    "    for i in kickers:\n",
    "        data_kicker = data.loc[data['Kicker'] == i]\n",
    "        success = data_kicker['Success'].value_counts()\n",
    "        try:\n",
    "            accuracy = success[1]/(success[1] + success[0])\n",
    "            accuracies.append({'Kicker' : i, 'Accuracy' : accuracy})\n",
    "        except KeyError:\n",
    "            accuracies.append({'Kicker': i, 'Accuracy' : np.nan})\n",
    "    return accuracies\n",
    "            \n",
    "results = data_per_kicker(kicker_list)\n",
    "frame = pd.DataFrame(results)\n",
    "frame.sort_values(ascending=False, by='Accuracy')\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d9f81fa",
   "metadata": {},
   "source": [
    "According to this metric in our Sample Boswell was the most accurate Kicker. Then again we shall not forget that this is merely an average of all kicks, hence the value is hugely influenced, by how many kicks the respective Kicker did. Kickers such as Elling, Coutu, and Scifres had not 1 successful kick in our sample. <br>\n",
    "2. Let's look at whether this accuracy varies if the Kicker changes teams\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "657504b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We use the same function as defined before.\n",
    "kicker_list = data['Kicker'].unique()\n",
    "\n",
    "def data_per_kicker(kickers):\n",
    "    accuracies = []\n",
    "    for i in kickers:\n",
    "        data_kicker = data.loc[data['Kicker'] == i]\n",
    "        success = data_kicker['Success'].value_counts()\n",
    "        try:\n",
    "            accuracy = success[1]/(success[1] + success[0])\n",
    "            accuracies.append({'Kicker' : i, 'Accuracy' : accuracy})\n",
    "        except KeyError:\n",
    "            accuracies.append({'Kicker': i, 'Accuracy' : np.nan})\n",
    "    return accuracies"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deep",
   "language": "python",
   "name": "deep"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
