{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "780a0c31",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import warnings\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "import seaborn as sns\n",
    "from stargazer.stargazer import Stargazer\n",
    "from sklearn.linear_model import LinearRegression, LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3c52864d",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('kickers_v2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "d78ef53b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Team</th>\n",
       "      <th>Year</th>\n",
       "      <th>GameMinute</th>\n",
       "      <th>Kicker</th>\n",
       "      <th>Distance</th>\n",
       "      <th>ScoreDiff</th>\n",
       "      <th>Grass</th>\n",
       "      <th>Success</th>\n",
       "      <th>Intercept</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>PHI</td>\n",
       "      <td>2005</td>\n",
       "      <td>3</td>\n",
       "      <td>Akers</td>\n",
       "      <td>49</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>PHI</td>\n",
       "      <td>2005</td>\n",
       "      <td>29</td>\n",
       "      <td>Akers</td>\n",
       "      <td>49</td>\n",
       "      <td>-7</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>PHI</td>\n",
       "      <td>2005</td>\n",
       "      <td>51</td>\n",
       "      <td>Akers</td>\n",
       "      <td>44</td>\n",
       "      <td>-7</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>PHI</td>\n",
       "      <td>2005</td>\n",
       "      <td>14</td>\n",
       "      <td>Akers</td>\n",
       "      <td>43</td>\n",
       "      <td>14</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>PHI</td>\n",
       "      <td>2005</td>\n",
       "      <td>60</td>\n",
       "      <td>Akers</td>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0 Team  Year  GameMinute Kicker  Distance  ScoreDiff  Grass  \\\n",
       "0           1  PHI  2005           3  Akers        49          0  False   \n",
       "1           2  PHI  2005          29  Akers        49         -7  False   \n",
       "2           3  PHI  2005          51  Akers        44         -7  False   \n",
       "3           4  PHI  2005          14  Akers        43         14   True   \n",
       "4           5  PHI  2005          60  Akers        23          0   True   \n",
       "\n",
       "   Success  Intercept  \n",
       "0        0          1  \n",
       "1        0          1  \n",
       "2        1          1  \n",
       "3        0          1  \n",
       "4        1          1  "
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "304ad0ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# It's important we check for NAN before we start our analysis.\n",
    "data.isnull().values.any()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "98907ad4",
   "metadata": {},
   "source": [
    "<h1> PSET 1 Econ 1042 Sports Economics </h1>\n",
    "<h2> 1. Question </h2>\n",
    "<ol>\n",
    "    <li> What was the minimum distance of a field goal kicked in this sample? What was the maximum? Mean? Median!</li>\n",
    "    <li> Why isn’t the minimum lower? (For those who are not familiar with football, please read about how field goal distance is measured and its relationship to where the ball is on the field.)</li>\n",
    "    <li> What special circumstances might explain the maximum? (Hint: football is a game with 4, 15-minute quarters. At the end of the second quarter there is a halftime break and possession is assigned based on the result of a first-half coin toss) </li>\n",
    "</ol>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6e467f50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The median distance of a field goal kicked was 37.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "count    11187.000000\n",
       "mean        36.897381\n",
       "std         10.173351\n",
       "min         18.000000\n",
       "25%         28.000000\n",
       "50%         37.000000\n",
       "75%         45.000000\n",
       "max         76.000000\n",
       "Name: Distance, dtype: float64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(f\"The median distance of a field goal kicked was {np.median(data['Distance'])}\")\n",
    "data['Distance'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "885af55a",
   "metadata": {},
   "source": [
    "1. The minimum distance of a field goal kicked in the sample was 18.00 yards. The maximum was 76.00 yards and the median was 37.0 yards. The mean was 36.897 yards\n",
    "2. The minimum is 17 yards. This makes sense since the endzone is 10yards, and the ball has to be kicked from 7 yards from the line of scrimmage. Hence 10 + 7 = 17."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2377c96d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Team</th>\n",
       "      <th>Year</th>\n",
       "      <th>GameMinute</th>\n",
       "      <th>Kicker</th>\n",
       "      <th>Distance</th>\n",
       "      <th>ScoreDiff</th>\n",
       "      <th>Grass</th>\n",
       "      <th>Success</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3557</th>\n",
       "      <td>3558</td>\n",
       "      <td>OAK</td>\n",
       "      <td>2008</td>\n",
       "      <td>30</td>\n",
       "      <td>Janikowski</td>\n",
       "      <td>76</td>\n",
       "      <td>15</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Unnamed: 0 Team  Year  GameMinute      Kicker  Distance  ScoreDiff  \\\n",
       "3557        3558  OAK  2008          30  Janikowski        76         15   \n",
       "\n",
       "      Grass  Success  \n",
       "3557   True        0  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Lets find out what play was kicked from 76 yards away?\n",
    "max_yard = data.loc[data['Distance'] == 76.00]\n",
    "max_yard"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b082f1c",
   "metadata": {},
   "source": [
    "3. The 76 yards field goal attempt from Janikowski was in the last second of the second quarter (video: https://www.youtube.com/watch?v=X7BepDe6Zoc). It makes sense to kick if far into the opponents end zone, if in the first half your team had the ball. Since, then the opposing team will start from further away from the kickers endzone. It's like as if the special team does a punt."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "671e0d2d",
   "metadata": {},
   "source": [
    "<h2> 2. Question </h2>\n",
    "<p> Over the entire sample what percentage of kicks from 40 to 45 yards were made? Kicks over 45 yards? <p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "3ddc13c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11187\n",
      "1325\n",
      "11.844% of Kicks were from between 40-45 yards\n"
     ]
    }
   ],
   "source": [
    "sample_size = len(data)\n",
    "print(sample_size)\n",
    "# let's find the number of successful kicks from 40-45 yards\n",
    "kicks_40_45 = data.loc[(data['Distance'] > 40) & (data['Distance'] < 45)]\n",
    "print(len(kicks_40_45))\n",
    "# We find that 1325 kicks were made in that range\n",
    "success_40_45 = kicks_40_45['Success'].value_counts()\n",
    "# print(success_40_45)\n",
    "ratio_success = success_40_45[1]/(success_40_45[0] + success_40_45[1])\n",
    "ratio = (len(kicks_40_45)/sample_size) * 100\n",
    "print(f'{ratio:.3f}% of Kicks were from between 40-45 yards')\n",
    "\n",
    "# How many kicks were over 45 yards?\n",
    "# kicks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "6aa068c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24.439% of Kicks were from between 40-45 yards\n"
     ]
    }
   ],
   "source": [
    "kicks_above_45 = data.loc[data['Distance'] > 45]\n",
    "ratio_above_45 = (len(kicks_above_45)/sample_size) * 100\n",
    "print(f'{ratio_above_45:.3f}% of Kicks were from between 40-45 yards')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9988943e",
   "metadata": {},
   "source": [
    "<h2> 3. Question </h2>\n",
    "<p> Was the make rate higher on grass or on turf? Is that difference statistically significant? Do you think this is the true effect of surface? Why or why not?  (Answer this by doing an OLS regression. For the entire assignment, let’s use the heteroskedasticity robust standard errors, r in stata or the equivalent in R)<br> <br>\n",
    "Let's compute the difference using $\\Delta = \\bar{Y}_{grass} - \\bar{Y}_{turf}$ we shall report standard errors as heteroscedasticity robust (HC2) \n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "dd985180",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                Success   R-squared:                       0.001\n",
      "Model:                            OLS   Adj. R-squared:                  0.001\n",
      "Method:                 Least Squares   F-statistic:                     7.500\n",
      "Date:                Sun, 29 Jan 2023   Prob (F-statistic):            0.00618\n",
      "Time:                        18:29:31   Log-Likelihood:                -4845.9\n",
      "No. Observations:               11187   AIC:                             9696.\n",
      "Df Residuals:                   11185   BIC:                             9710.\n",
      "Df Model:                           1                                         \n",
      "Covariance Type:                  HC2                                         \n",
      "==============================================================================\n",
      "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "Grass         -0.0193      0.007     -2.739      0.006      -0.033      -0.005\n",
      "Intercept      0.8433      0.005    164.864      0.000       0.833       0.853\n",
      "==============================================================================\n",
      "Omnibus:                     3155.584   Durbin-Watson:                   1.995\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):             6555.427\n",
      "Skew:                          -1.781   Prob(JB):                         0.00\n",
      "Kurtosis:                       4.175   Cond. No.                         2.75\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors are heteroscedasticity robust (HC2)\n"
     ]
    }
   ],
   "source": [
    "# define response variable\n",
    "# statsmodel requires us to add a column where each value is 1 in order to compute intercept\n",
    "data['Intercept'] = 1\n",
    "# Since we find no NAN in our column\n",
    "print(data['Grass'].isnull().values.any())\n",
    "# We can conver the 'bool' values for Grass to the datatype 'int'\n",
    "data['Grass'] = data['Grass'].astype(int)\n",
    "Y = data[['Success']]\n",
    "X = data[['Grass', 'Intercept']]\n",
    "mod = sm.OLS(Y, X)\n",
    "res = mod.fit(cov_type='HC2')\n",
    "print(res.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "1bb9edef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.01932925]]\n"
     ]
    }
   ],
   "source": [
    "# Let's also try the Sklearn Library\n",
    "# We can also use the Sklearn Library to do an OLS regression, but I don't think it has a summary function.\n",
    "X = data[['Grass']]\n",
    "reg = LinearRegression(fit_intercept=True).fit(X,Y)\n",
    "parameters = reg.get_params()\n",
    "print(reg.coef_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e4878e3",
   "metadata": {},
   "source": [
    "We find that the observed difference is statistically insignificant at the $\\alpha = 0.05$ level. It seems as if the surface does not have an impact on the observed average success rates of field goal kicks."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "171f63be",
   "metadata": {},
   "source": [
    "<h2> 4. Question </h2>\n",
    "<ol>\n",
    "    <li>\tHow is distance of attempt correlated with surface? What might explain this? (Coaches get to choose when to kick a field goal, one is never forced) </li>\n",
    "    <li> \tHow is distance correlated with make percentage? </li>\n",
    "</ol>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "5f886e8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.002551996001227438\n",
      "-0.33693399701495164\n"
     ]
    }
   ],
   "source": [
    "# Let's calculate the correlation between the columns\n",
    "corr_surface = data['Distance'].corr(data['Grass'])\n",
    "corr_success = data['Distance'].corr(data['Success'])\n",
    "print(corr_surface)\n",
    "print(corr_success)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cac743f",
   "metadata": {},
   "source": [
    "The correlation coefficient for distance and or Grass is -0.0025, basically negligible. The correlation coefficiecnt for distance and success rates is -0.3369, meaning as distance increases the success rate goes down. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3f82c10",
   "metadata": {},
   "source": [
    "<h2> 5. Question </h2>\n",
    "<ol>\n",
    "    <li>What is the formula for omitted variable bias?</li>\n",
    "    <li><strong>Given (a) what should happen to the estimate of the effect of a kick being on grass when you add in distance? Verify this is true.</li>\n",
    "</ol>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ae29347",
   "metadata": {},
   "source": [
    "1. Ommitted variable bias arises when the regressor X is correlated with an omitted variable.\n",
    "The formula for omitted variable bias is <br>$\\hat{\\beta}_{1,OLS}= \\frac{Cov(y,x_1)}{Var(x_1)}$\n",
    "2. We can estimate the effect of the ommited bias by adding in distance. Since, success rate and grass type are uncorrelated, we should be able to see <strong> NO IDEA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "06b38d32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                Success   R-squared:                       0.114\n",
      "Model:                            OLS   Adj. R-squared:                  0.114\n",
      "Method:                 Least Squares   F-statistic:                     695.7\n",
      "Date:                Mon, 30 Jan 2023   Prob (F-statistic):          1.74e-285\n",
      "Time:                        13:08:40   Log-Likelihood:                -4171.1\n",
      "No. Observations:               11187   AIC:                             8348.\n",
      "Df Residuals:                   11184   BIC:                             8370.\n",
      "Df Model:                           2                                         \n",
      "Covariance Type:                  HC2                                         \n",
      "==============================================================================\n",
      "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "Grass         -0.0200      0.007     -3.004      0.003      -0.033      -0.007\n",
      "Distance      -0.0124      0.000    -37.218      0.000      -0.013      -0.012\n",
      "Intercept      1.2999      0.011    115.413      0.000       1.278       1.322\n",
      "==============================================================================\n",
      "Omnibus:                     2395.590   Durbin-Watson:                   1.982\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):             4232.201\n",
      "Skew:                          -1.449   Prob(JB):                         0.00\n",
      "Kurtosis:                       3.824   Cond. No.                         152.\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors are heteroscedasticity robust (HC2)\n"
     ]
    }
   ],
   "source": [
    "Y = data[['Success']]\n",
    "X = data[['Grass', 'Distance', 'Intercept']]\n",
    "mod = sm.OLS(Y, X)\n",
    "res = mod.fit(cov_type='HC2')\n",
    "print(res.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "bcbafa82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                Success   R-squared:                       0.114\n",
      "Model:                            OLS   Adj. R-squared:                  0.114\n",
      "Method:                 Least Squares   F-statistic:                     695.7\n",
      "Date:                Mon, 30 Jan 2023   Prob (F-statistic):          1.74e-285\n",
      "Time:                        13:08:37   Log-Likelihood:                -4171.1\n",
      "No. Observations:               11187   AIC:                             8348.\n",
      "Df Residuals:                   11184   BIC:                             8370.\n",
      "Df Model:                           2                                         \n",
      "Covariance Type:                  HC2                                         \n",
      "==============================================================================\n",
      "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "Intercept      1.2999      0.011    115.413      0.000       1.278       1.322\n",
      "Grass         -0.0200      0.007     -3.004      0.003      -0.033      -0.007\n",
      "Distance      -0.0124      0.000    -37.218      0.000      -0.013      -0.012\n",
      "==============================================================================\n",
      "Omnibus:                     2395.590   Durbin-Watson:                   1.982\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):             4232.201\n",
      "Skew:                          -1.449   Prob(JB):                         0.00\n",
      "Kurtosis:                       3.824   Cond. No.                         152.\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors are heteroscedasticity robust (HC2)\n"
     ]
    }
   ],
   "source": [
    "mod = smf.ols(formula='Success ~ Grass + Distance', data=data).fit(cov_type='HC2')\n",
    "print(mod.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "da29a21c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Unnamed: 0', 'Team', 'Year', 'GameMinute', 'Kicker', 'Distance',\n",
       "       'ScoreDiff', 'Grass', 'Success', 'Intercept'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "9d807301",
   "metadata": {},
   "source": [
    "<h2> 6. Question </h2>\n",
    "<ol>\n",
    "    <li> Run an ols regression of kick success on distance, surface, point differential, and clock time. Interpret the coefficients. Does it seem like kickers do better or worse late in the game? Does the score of the game seem to effect them?</li>\n",
    "\n",
    "<li>Now add in kicker fixed effects (i.kicker in Stata), what do these correct for? How does adjusted r-squared change? </li>\n",
    "</ol>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "ee316d1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                Success   R-squared:                       0.114\n",
      "Model:                            OLS   Adj. R-squared:                  0.114\n",
      "Method:                 Least Squares   F-statistic:                     347.8\n",
      "Date:                Mon, 30 Jan 2023   Prob (F-statistic):          1.07e-282\n",
      "Time:                        13:25:48   Log-Likelihood:                -4171.0\n",
      "No. Observations:               11187   AIC:                             8352.\n",
      "Df Residuals:                   11182   BIC:                             8389.\n",
      "Df Model:                           4                                         \n",
      "Covariance Type:                  HC2                                         \n",
      "==============================================================================\n",
      "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "Intercept      1.2987      0.013    101.462      0.000       1.274       1.324\n",
      "Distance      -0.0124      0.000    -37.158      0.000      -0.013      -0.012\n",
      "Grass         -0.0200      0.007     -3.004      0.003      -0.033      -0.007\n",
      "ScoreDiff     -0.0001      0.000     -0.285      0.776      -0.001       0.001\n",
      "GameMinute  4.408e-05      0.000      0.221      0.825      -0.000       0.000\n",
      "==============================================================================\n",
      "Omnibus:                     2395.605   Durbin-Watson:                   1.981\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):             4232.237\n",
      "Skew:                          -1.449   Prob(JB):                         0.00\n",
      "Kurtosis:                       3.824   Cond. No.                         225.\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors are heteroscedasticity robust (HC2)\n"
     ]
    }
   ],
   "source": [
    "mod = smf.ols(formula='Success ~ Distance + Grass + ScoreDiff + GameMinute', data=data).fit(cov_type='HC2')\n",
    "print(mod.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "335a421b",
   "metadata": {},
   "source": [
    "<p>1. The Game minute seems to have no statistically significant effect on Kicker performance. Furthermore, the point differential of the game does not seem to be statistically significant either, and also not affecting kicker success rates.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "fcb958b5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                Success   R-squared:                       0.127\n",
      "Model:                            OLS   Adj. R-squared:                  0.121\n",
      "Method:                 Least Squares   F-statistic:                 8.581e+10\n",
      "Date:                Mon, 30 Jan 2023   Prob (F-statistic):               0.00\n",
      "Time:                        13:30:56   Log-Likelihood:                -4088.0\n",
      "No. Observations:               11187   AIC:                             8350.\n",
      "Df Residuals:                   11100   BIC:                             8987.\n",
      "Df Model:                          86                                         \n",
      "Covariance Type:                  HC2                                         \n",
      "===========================================================================================\n",
      "                              coef    std err          z      P>|z|      [0.025      0.975]\n",
      "-------------------------------------------------------------------------------------------\n",
      "Intercept                   1.2659      0.024     53.087      0.000       1.219       1.313\n",
      "C(Kicker)[T.Andersen]       0.0438      0.047      0.937      0.349      -0.048       0.136\n",
      "C(Kicker)[T.Andrus]        -0.3664      0.216     -1.693      0.090      -0.791       0.058\n",
      "C(Kicker)[T.Bailey]         0.1116      0.031      3.578      0.000       0.050       0.173\n",
      "C(Kicker)[T.Barth]          0.0775      0.033      2.337      0.019       0.013       0.142\n",
      "C(Kicker)[T.Bironas]        0.0760      0.029      2.668      0.008       0.020       0.132\n",
      "C(Kicker)[T.Boswell]        0.1248      0.046      2.693      0.007       0.034       0.216\n",
      "C(Kicker)[T.Brien]         -0.4597      0.275     -1.674      0.094      -0.998       0.079\n",
      "C(Kicker)[T.Brindza]       -0.2372      0.153     -1.553      0.121      -0.537       0.062\n",
      "C(Kicker)[T.Brown]          0.0311      0.026      1.188      0.235      -0.020       0.082\n",
      "C(Kicker)[T.Bryant]         0.0572      0.028      2.079      0.038       0.003       0.111\n",
      "C(Kicker)[T.Buehler]       -0.0320      0.078     -0.411      0.681      -0.184       0.120\n",
      "C(Kicker)[T.Bullock]        0.0350      0.044      0.801      0.423      -0.051       0.121\n",
      "C(Kicker)[T.Carney]         0.0037      0.035      0.105      0.916      -0.065       0.073\n",
      "C(Kicker)[T.Carpenter]      0.0690      0.029      2.375      0.018       0.012       0.126\n",
      "C(Kicker)[T.Catanzaro]      0.0925      0.040      2.292      0.022       0.013       0.172\n",
      "C(Kicker)[T.Coons]          0.0628      0.055      1.150      0.250      -0.044       0.170\n",
      "C(Kicker)[T.Cortez]        -0.1175      0.108     -1.085      0.278      -0.330       0.095\n",
      "C(Kicker)[T.Coutu]         -0.7064      0.022    -32.777      0.000      -0.749      -0.664\n",
      "C(Kicker)[T.Crosby]         0.0113      0.029      0.392      0.695      -0.045       0.068\n",
      "C(Kicker)[T.Cundiff]       -0.0331      0.035     -0.943      0.346      -0.102       0.036\n",
      "C(Kicker)[T.Dawson]         0.0607      0.027      2.220      0.026       0.007       0.114\n",
      "C(Kicker)[T.Edinger]       -0.0719      0.079     -0.915      0.360      -0.226       0.082\n",
      "C(Kicker)[T.Elam]           0.0350      0.035      1.004      0.315      -0.033       0.103\n",
      "C(Kicker)[T.Elling]        -0.5950      0.023    -25.669      0.000      -0.640      -0.550\n",
      "C(Kicker)[T.Feely]          0.0476      0.029      1.634      0.102      -0.010       0.105\n",
      "C(Kicker)[T.Folk]           0.0112      0.031      0.363      0.717      -0.050       0.072\n",
      "C(Kicker)[T.Forbath]        0.0543      0.045      1.213      0.225      -0.033       0.142\n",
      "C(Kicker)[T.France]        -0.0472      0.134     -0.353      0.724      -0.309       0.215\n",
      "C(Kicker)[T.Franks]         0.0361      0.091      0.398      0.691      -0.142       0.214\n",
      "C(Kicker)[T.Freese]        -0.3562      0.159     -2.245      0.025      -0.667      -0.045\n",
      "C(Kicker)[T.Gano]           0.0173      0.034      0.510      0.610      -0.049       0.084\n",
      "C(Kicker)[T.Gostkowski]     0.0601      0.027      2.238      0.025       0.007       0.113\n",
      "C(Kicker)[T.Gould]          0.0664      0.027      2.448      0.014       0.013       0.120\n",
      "C(Kicker)[T.Graham]         0.0374      0.029      1.311      0.190      -0.019       0.093\n",
      "C(Kicker)[T.Gramatica]      0.0166      0.083      0.200      0.842      -0.147       0.180\n",
      "C(Kicker)[T.Hall]           0.0287      0.071      0.402      0.687      -0.111       0.168\n",
      "C(Kicker)[T.Hanson]         0.0673      0.031      2.181      0.029       0.007       0.128\n",
      "C(Kicker)[T.Hartley]        0.0105      0.041      0.257      0.797      -0.070       0.091\n",
      "C(Kicker)[T.Hauschka]       0.0743      0.030      2.445      0.014       0.015       0.134\n",
      "C(Kicker)[T.Henery]         0.0183      0.042      0.440      0.660      -0.063       0.100\n",
      "C(Kicker)[T.Hocker]        -0.0916      0.118     -0.775      0.438      -0.323       0.140\n",
      "C(Kicker)[T.Hopkins]        0.1042      0.056      1.861      0.063      -0.006       0.214\n",
      "C(Kicker)[T.Janikowski]     0.0514      0.029      1.802      0.072      -0.005       0.107\n",
      "C(Kicker)[T.Kaeding]        0.0432      0.031      1.396      0.163      -0.017       0.104\n",
      "C(Kicker)[T.Kasay]          0.0653      0.030      2.186      0.029       0.007       0.124\n",
      "C(Kicker)[T.Koenen]        -0.4115      0.137     -3.005      0.003      -0.680      -0.143\n",
      "C(Kicker)[T.Lambo]          0.0743      0.067      1.101      0.271      -0.058       0.207\n",
      "C(Kicker)[T.Lindell]        0.0325      0.030      1.086      0.277      -0.026       0.091\n",
      "C(Kicker)[T.Longwell]       0.0408      0.032      1.268      0.205      -0.022       0.104\n",
      "C(Kicker)[T.Mare]          -0.0100      0.033     -0.301      0.763      -0.075       0.055\n",
      "C(Kicker)[T.McManus]        0.0631      0.049      1.295      0.195      -0.032       0.159\n",
      "C(Kicker)[T.Medlock]       -0.1423      0.131     -1.083      0.279      -0.400       0.115\n",
      "C(Kicker)[T.Mehlhaff]      -0.1027      0.264     -0.388      0.698      -0.621       0.416\n",
      "C(Kicker)[T.Murray]         0.1003      0.086      1.165      0.244      -0.068       0.269\n",
      "C(Kicker)[T.Myers]          0.0621      0.066      0.946      0.344      -0.067       0.191\n",
      "C(Kicker)[T.Nedney]         0.0743      0.033      2.231      0.026       0.009       0.140\n",
      "C(Kicker)[T.Novak]          0.0325      0.034      0.963      0.336      -0.034       0.099\n",
      "C(Kicker)[T.Nugent]         0.0083      0.030      0.275      0.783      -0.051       0.068\n",
      "C(Kicker)[T.Parkey]         0.0666      0.055      1.205      0.228      -0.042       0.175\n",
      "C(Kicker)[T.Peterson]       0.0538      0.057      0.943      0.345      -0.058       0.165\n",
      "C(Kicker)[T.Pettrey]       -0.4034      0.253     -1.597      0.110      -0.899       0.092\n",
      "C(Kicker)[T.Potter]        -0.0665      0.203     -0.328      0.743      -0.465       0.331\n",
      "C(Kicker)[T.Prater]         0.0531      0.031      1.718      0.086      -0.007       0.114\n",
      "C(Kicker)[T.Rackers]        0.0531      0.029      1.801      0.072      -0.005       0.111\n",
      "C(Kicker)[T.Rayner]        -0.0642      0.050     -1.293      0.196      -0.161       0.033\n",
      "C(Kicker)[T.Reed]           0.0236      0.032      0.731      0.465      -0.040       0.087\n",
      "C(Kicker)[T.Santos]         0.0574      0.045      1.283      0.200      -0.030       0.145\n",
      "C(Kicker)[T.Schmitt]       -0.1605      0.368     -0.436      0.663      -0.881       0.560\n",
      "C(Kicker)[T.Scifres]        0.2547      0.021     12.298      0.000       0.214       0.295\n",
      "C(Kicker)[T.Scobee]         0.0329      0.030      1.088      0.277      -0.026       0.092\n",
      "C(Kicker)[T.Stitser]       -0.0093      0.135     -0.068      0.946      -0.275       0.256\n",
      "C(Kicker)[T.Stover]         0.0453      0.032      1.403      0.161      -0.018       0.109\n",
      "C(Kicker)[T.Sturgis]        0.0080      0.044      0.180      0.857      -0.079       0.095\n",
      "C(Kicker)[T.Succop]         0.0420      0.033      1.272      0.203      -0.023       0.107\n",
      "C(Kicker)[T.Suisham]        0.0298      0.030      1.005      0.315      -0.028       0.088\n",
      "C(Kicker)[T.Tucker]         0.1047      0.031      3.350      0.001       0.043       0.166\n",
      "C(Kicker)[T.Tynes]         -0.0130      0.032     -0.408      0.683      -0.075       0.049\n",
      "C(Kicker)[T.Vanderjagt]    -0.0203      0.058     -0.349      0.727      -0.134       0.094\n",
      "C(Kicker)[T.Vinatieri]      0.0619      0.027      2.275      0.023       0.009       0.115\n",
      "C(Kicker)[T.Walsh]          0.0711      0.035      2.031      0.042       0.002       0.140\n",
      "C(Kicker)[T.Wilkins]        0.0438      0.042      1.043      0.297      -0.039       0.126\n",
      "C(Kicker)[T.Zuerlein]       0.0277      0.041      0.681      0.496      -0.052       0.107\n",
      "Distance                   -0.0125      0.000    -37.174      0.000      -0.013      -0.012\n",
      "Grass                      -0.0246      0.007     -3.314      0.001      -0.039      -0.010\n",
      "ScoreDiff               -3.034e-05      0.000     -0.083      0.934      -0.001       0.001\n",
      "GameMinute               4.117e-05      0.000      0.207      0.836      -0.000       0.000\n",
      "==============================================================================\n",
      "Omnibus:                     2348.948   Durbin-Watson:                   2.007\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):             4107.577\n",
      "Skew:                          -1.426   Prob(JB):                         0.00\n",
      "Kurtosis:                       3.827   Cond. No.                     5.45e+03\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors are heteroscedasticity robust (HC2)\n",
      "[2] The condition number is large, 5.45e+03. This might indicate that there are\n",
      "strong multicollinearity or other numerical problems.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/deep/lib/python3.10/site-packages/statsmodels/base/model.py:1871: ValueWarning: covariance of constraints does not have full rank. The number of constraints is 86, but rank is 85\n",
      "  warnings.warn('covariance of constraints does not have full '\n"
     ]
    }
   ],
   "source": [
    "mod = smf.ols(formula='Success ~ Distance + Grass + ScoreDiff + GameMinute + C(Kicker)', data=data).fit(cov_type='HC2')\n",
    "print(mod.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb7bcc99",
   "metadata": {},
   "source": [
    "<p> 2. Adjusted R-square goes up, since we adjusting our regression for individuals attributes that do not vary over the time of a season(sample size)."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "685ebdb9",
   "metadata": {},
   "source": [
    "<h2> 7. Question </h2>\n",
    "<ol>\n",
    "    <li> After you run the regression in part 6, do the command to predict fitted values from this regression: “predict, xb” in stata and equivalent in R “predict.lm”. Based on this, what would you predict the probability of Justin Tucker cutting the lead to 8 (scorediff was -11) in 2015, when the gameminute was 30, and he was on turf</li>\n",
    "    <ol>\n",
    "        <li> We can't build a model using all inputs, and then try to predict sth when missing one value. Missing here is an input for the <strong>Distance</li>\n",
    "    </ol>\n",
    "\n",
    "<li>Does this estimate strike you as reasonable?</li>\n",
    "<li>What would the estimate be for an average kicker?</li>\n",
    "</ol>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "id": "e475672d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Linear_Tucker', -0.012015139013776488, 0.09939115007000607, 0.0008766873127663746, 0.0007538568196675142, 0.9350746758606505]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/deep/lib/python3.10/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but LinearRegression was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Distance</th>\n",
       "      <th>Grass</th>\n",
       "      <th>ScoreDiff</th>\n",
       "      <th>GameMinute</th>\n",
       "      <th>Proba</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Linear_Tucker</td>\n",
       "      <td>-0.012015</td>\n",
       "      <td>0.099391</td>\n",
       "      <td>0.000877</td>\n",
       "      <td>0.000754</td>\n",
       "      <td>0.935075</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Model  Distance     Grass  ScoreDiff  GameMinute     Proba\n",
       "0  Linear_Tucker -0.012015  0.099391   0.000877    0.000754  0.935075"
      ]
     },
     "execution_count": 223,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's use the Sklearn library for this prediction. Since we can specify the input.\n",
    "# Since we are interested in Tucker\n",
    "data_tucker = data.loc[data['Kicker'] == 'Tucker']\n",
    "X = data_tucker[['Distance', 'Grass', 'ScoreDiff', 'GameMinute']]\n",
    "Y = data_tucker[['Success']]\n",
    "reg = LinearRegression(fit_intercept=True).fit(X,Y)\n",
    "parameters = reg.get_params()\n",
    "# Let's find the distance of the kick from tucker with scroediff -11, gameminute 30, and on turf\n",
    "tucker = data_tucker.loc[(data_tucker['ScoreDiff']==-11)&(data_tucker['GameMinute']==30) & (data_tucker['Grass']==False)]\n",
    "tucker\n",
    "\n",
    "reg_coef = list(np.ravel(reg.coef_))\n",
    "reg_coef.insert(0, 'Linear_Tucker')\n",
    "proba = reg.predict([[30, False, -11, 30]])[0][0]\n",
    "reg_coef.append(proba)\n",
    "print(reg_coef)\n",
    "results = pd.DataFrame([reg_coef], columns=['Model', 'Distance', 'Grass', 'ScoreDiff', 'GameMinute', 'Proba'])\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "id": "5dfa1c23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9350746758606505\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/deep/lib/python3.10/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but LinearRegression was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# This is the play that the question is asking for\n",
    "# We can ignore the warning message\n",
    "tucker = [[30, False, -11, 30]]\n",
    "print(reg.predict(tucker)[0][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5023ef4",
   "metadata": {},
   "source": [
    "2. Let's see if this estimate seems reasonable for Tucker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "4f99f6f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    61\n",
       "Name: Success, dtype: int64"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tucker_35_yards = data_tucker.loc[(data_tucker['Distance'] < 35)]\n",
    "tucker_35_yards['Success'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "779d7e09",
   "metadata": {},
   "source": [
    "In the sample Tucker made $61$ kicks that were below 35 yards and he made every single one of them. Hence, the estimate in 1.) seems reasonable. On average in the sample we have $4765$ observations of Kicks that were shot at less then 35 yard distance. Of those $0.947\\%$ were successful, hence the predicted probability seems to be a reasonable estimate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "85054ece",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    4513\n",
       "0     252\n",
       "Name: Success, dtype: int64"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_35_yards = data.loc[data['Distance'] < 35]\n",
    "data_35_yards['Success'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ace9ee9e",
   "metadata": {},
   "source": [
    "3. Let's predict the probability for an average kicker for that same shot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "id": "23a90f24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Linear', -0.012371812687093085, -0.01997241577141623, -0.0001022378401408906, 4.407522836155251e-05, 0.9300106512280658]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/deep/lib/python3.10/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but LinearRegression was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Distance</th>\n",
       "      <th>Grass</th>\n",
       "      <th>ScoreDiff</th>\n",
       "      <th>GameMinute</th>\n",
       "      <th>Proba</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Linear</td>\n",
       "      <td>-0.012372</td>\n",
       "      <td>-0.019972</td>\n",
       "      <td>-0.000102</td>\n",
       "      <td>0.000044</td>\n",
       "      <td>0.930011</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Model  Distance     Grass  ScoreDiff  GameMinute     Proba\n",
       "0  Linear -0.012372 -0.019972  -0.000102    0.000044  0.930011"
      ]
     },
     "execution_count": 219,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = data[['Distance', 'Grass', 'ScoreDiff', 'GameMinute']]\n",
    "Y = data[['Success']]\n",
    "reg = LinearRegression(fit_intercept=True).fit(X,Y)\n",
    "parameters = reg.get_params()\n",
    "reg_coef = list(np.ravel(reg.coef_))\n",
    "reg_coef.insert(0, 'Linear')\n",
    "proba = reg.predict([[30, False, -11, 30]])[0][0]\n",
    "reg_coef.append(proba)\n",
    "print(reg_coef)\n",
    "results = pd.DataFrame([reg_coef], columns=['Model', 'Distance', 'Grass', 'ScoreDiff', 'GameMinute', 'Proba'])\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51f9f84a",
   "metadata": {},
   "source": [
    "We estimate the probability for an average kicker to be 0.93%"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a2c322b",
   "metadata": {},
   "source": [
    "<hr>\n",
    "<h2> 8. Question </h2>\n",
    "<ol>\n",
    "    <li>Now run a logistic regression with the same specification as in question 6. Use the command predict. Now what is the predicted probability of Tucker making that field goal? (the predict command in stata is now just “predict”)</li>\n",
    "    <li>Why do the coefficients look so different for the logistic regression vs. OLS </li>\n",
    "</ol>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "id": "0b510287",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Logistic', -0.10284160933932229, -0.16762221135876101, -0.0009622082796419989, 0.0003842398038772469]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/deep/lib/python3.10/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but LogisticRegression was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Shape of passed values is (5, 1), indices imply (5, 4)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[0;32mIn [215]\u001b[0m, in \u001b[0;36m<cell line: 9>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m model_log_coef\u001b[38;5;241m.\u001b[39minsert(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLogistic\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28mprint\u001b[39m(model_log_coef)\n\u001b[0;32m----> 9\u001b[0m frame \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mDataFrame\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_log_coef\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mDistance\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mGrass\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mScoreDiff\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mGameMinute\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     10\u001b[0m frame\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/deep/lib/python3.10/site-packages/pandas/core/frame.py:761\u001b[0m, in \u001b[0;36mDataFrame.__init__\u001b[0;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[1;32m    753\u001b[0m         mgr \u001b[38;5;241m=\u001b[39m arrays_to_mgr(\n\u001b[1;32m    754\u001b[0m             arrays,\n\u001b[1;32m    755\u001b[0m             columns,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    758\u001b[0m             typ\u001b[38;5;241m=\u001b[39mmanager,\n\u001b[1;32m    759\u001b[0m         )\n\u001b[1;32m    760\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 761\u001b[0m         mgr \u001b[38;5;241m=\u001b[39m \u001b[43mndarray_to_mgr\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    762\u001b[0m \u001b[43m            \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    763\u001b[0m \u001b[43m            \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    764\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    765\u001b[0m \u001b[43m            \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    766\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    767\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtyp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmanager\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    768\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    769\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    770\u001b[0m     mgr \u001b[38;5;241m=\u001b[39m dict_to_mgr(\n\u001b[1;32m    771\u001b[0m         {},\n\u001b[1;32m    772\u001b[0m         index,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    775\u001b[0m         typ\u001b[38;5;241m=\u001b[39mmanager,\n\u001b[1;32m    776\u001b[0m     )\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/deep/lib/python3.10/site-packages/pandas/core/internals/construction.py:349\u001b[0m, in \u001b[0;36mndarray_to_mgr\u001b[0;34m(values, index, columns, dtype, copy, typ)\u001b[0m\n\u001b[1;32m    344\u001b[0m \u001b[38;5;66;03m# _prep_ndarraylike ensures that values.ndim == 2 at this point\u001b[39;00m\n\u001b[1;32m    345\u001b[0m index, columns \u001b[38;5;241m=\u001b[39m _get_axes(\n\u001b[1;32m    346\u001b[0m     values\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m], values\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m], index\u001b[38;5;241m=\u001b[39mindex, columns\u001b[38;5;241m=\u001b[39mcolumns\n\u001b[1;32m    347\u001b[0m )\n\u001b[0;32m--> 349\u001b[0m \u001b[43m_check_values_indices_shape_match\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    351\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m typ \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124marray\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    353\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28missubclass\u001b[39m(values\u001b[38;5;241m.\u001b[39mdtype\u001b[38;5;241m.\u001b[39mtype, \u001b[38;5;28mstr\u001b[39m):\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/deep/lib/python3.10/site-packages/pandas/core/internals/construction.py:420\u001b[0m, in \u001b[0;36m_check_values_indices_shape_match\u001b[0;34m(values, index, columns)\u001b[0m\n\u001b[1;32m    418\u001b[0m passed \u001b[38;5;241m=\u001b[39m values\u001b[38;5;241m.\u001b[39mshape\n\u001b[1;32m    419\u001b[0m implied \u001b[38;5;241m=\u001b[39m (\u001b[38;5;28mlen\u001b[39m(index), \u001b[38;5;28mlen\u001b[39m(columns))\n\u001b[0;32m--> 420\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mShape of passed values is \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpassed\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, indices imply \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mimplied\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mValueError\u001b[0m: Shape of passed values is (5, 1), indices imply (5, 4)"
     ]
    }
   ],
   "source": [
    "X = data[['Distance', 'Grass', 'ScoreDiff', 'GameMinute']]\n",
    "Y = data['Success']\n",
    "model_log = LogisticRegression(fit_intercept=True).fit(X,Y)\n",
    "parameters = model_log.get_params()\n",
    "model_log.predict_proba([[30, False, -11, 30]])\n",
    "model_log_coef = list(np.ravel(model_log.coef_))\n",
    "model_log_coef.insert(0, 'Logistic')\n",
    "print(model_log_coef)\n",
    "frame = pd.DataFrame(model_log_coef, columns=['Distance', 'Grass', 'ScoreDiff', 'GameMinute'])\n",
    "frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36d086f9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deep",
   "language": "python",
   "name": "deep"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
